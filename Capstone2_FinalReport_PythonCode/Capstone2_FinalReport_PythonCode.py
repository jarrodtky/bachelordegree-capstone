# -*- coding: utf-8 -*-
"""Capstone2_PythonCode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BAVnAIFhsR2FAgMP9w4yIlRCMO94ozZl

#INSTALL LIBRARY
"""

# Pip install/update these packages/modules if they're not yet installed/updated.
#!pip install openpyxl==3.0.5
#!pip install pandas==1.2.4

# Import Python Library

# To read, save, or load the dataset
import pandas as pd
import csv

# Data Preprocessing
import re 
import string
import numpy as np 
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
import nltk as nlp
import nltk.corpus
from nltk.corpus import stopwords
from nltk import word_tokenize
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from collections import Counter
from nltk.util import everygrams
from nltk.stem.porter import PorterStemmer
from nltk.tokenize import word_tokenize 
import pickle as pk
from scipy import sparse as sp

# Text Manipulation
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.tokenize import RegexpTokenizer

# For general visualizations / text analysis
import seaborn as sns
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from wordcloud import WordCloud 
import plotly.express as px
import plotly.figure_factory as ff
plt.style.use('fivethirtyeight')

# For classification and sentiment analysis
from textblob import TextBlob
from sklearn import feature_extraction, linear_model, model_selection, preprocessing, metrics
from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV 
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import mean_squared_error, mean_absolute_error, log_loss, accuracy_score, precision_score, confusion_matrix, classification_report, roc_auc_score, roc_curve,auc
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier
from sklearn.pipeline import Pipeline

import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)

# Using pandas library and 'read_excel' function to read Capstone2_FinalReport_Dataset.xlsx file into Python.
df = pd.read_excel('Capstone2_FinalReport_Dataset.xlsx')

# Displays the first 20 rows from the listings dataset with all variables as example.
df.head(20)

# prints the number of variables and observations of the listings dataset.
print('Number of variables: {}'.format(df.shape[1]))
print('Number of observations: {}'.format(df.shape[0]))

# shows the basic information of the variables.
df.info()



#Checking which variable contains null or missing values.
df.isnull().sum()

"""#DATA PREPROCESSING"""

# Dropping variables for future data exploration and analysis.
df.drop(['Title', 'Area'], axis=1, inplace=True)

# Change the datatype of Date and Feature it into Year and Month
import datetime

df['Date'] = pd.to_datetime(df['Date'])

df['YDate'], df['MDate'] = df['Date'].dt.year, df['Date'].dt.month

df

# Investigate all the elements whithin each Feature 
#How many unique values are they , and what are they  ? 

#efficient and scalable way
for column in df:
    unique_values = np.unique(df[column])
    unique_count = len(unique_values)
    if unique_count <= 10:
        print("The number of values for feature {} is: {} -- {}".format(column, unique_count, unique_values))
    else:
        print("The number of values for feature {} is: {}".format(column, unique_count))

#convert text to lowercase 
#removing numbers 
#removing punctuation 
#removing stop words
#Lemmatization
#filter out single characters 
cleaned_reviews_list = []
for cleaned_reviews in df.Review:
    cleaned_reviews = re.sub("[^a-zA-Z]", " ", cleaned_reviews)
    cleaned_reviews = cleaned_reviews.lower()
    cleaned_reviews = nltk.word_tokenize(cleaned_reviews)
    cleaned_reviews = [word for word in cleaned_reviews if not word in 
                    set(stopwords.words("english"))]
    lemma = nlp.WordNetLemmatizer()
    cleaned_reviews = [lemma.lemmatize(word) for word in cleaned_reviews]
    cleaned_reviews = " ".join(w for w in cleaned_reviews if len(w) > 1)
    cleaned_reviews_list.append(cleaned_reviews)

# Save and display data in new column
df["Review_clean"] = cleaned_reviews_list
df.head(10)

# Removing whitespaces by splitting Review_clean for counter
def split_name(Review_clean):
    split = str(Review_clean).split()
    return split

# Store the data in a list for text visualization
reviews_count_list = []
for x in cleaned_reviews_list:
    for y in split_name(x):
        reviews_count_list.append(y)

"""

> SENTIMENT DATA PREPARATION
"""

# Create a function to get the subjectivity
def getSubjectivity(Review_clean): 
  return TextBlob(Review_clean).sentiment.subjectivity

# Create a function to get the polarity
def getPolarity(Review_clean): 
  return TextBlob(Review_clean).sentiment.polarity

# Create two new columns
df['Subjectivity'] = df['Review_clean'].apply(getSubjectivity)
df['Polarity'] = df['Review_clean'].apply(getPolarity)

# Show the new dataframe with the new columns
df.head(10)

# Create a function to compute the negative, neutral and positive analysis
def getAnalysis(score): 
  if score < 0: 
    return "Negative" 
  elif score == 0:
    return "Neutral" 
  else:
    return "Positive" 
  
df['Sentiment'] = df['Polarity'].apply(getAnalysis)

df.head(10)

# Create a function to compute the negative, neutral and positive analysis
def getAnalysis(score): 
  if score < 0: 
    return -1 #negative
  elif score == 0:
    return 0 #neutral
  else:
    return 1 #positive
  
df['Analysis'] = df['Polarity'].apply(getAnalysis)

df.head(10)

df.Analysis.value_counts()

df.Analysis.value_counts(normalize=True)

df.info()

"""#EXPLORATORY DATA ANALYSIS

"""

class_dist = df['Rating'].value_counts()

def ditribution_plot(x,y,name):
    fig = go.Figure([
        go.Bar(x=x, y=y)
    ])

    fig.update_layout(title_text=name)
    fig.show()

ditribution_plot(x= class_dist.index, y= class_dist.values, name= 'Rating Distribution of Data')

sns.countplot(df['Rating'])

# l is the list which has the names of the labels which is 1,2,3,4,5 and y is the count of these labels
l=[]
r=[]
for i in range(1,6):
    l.append(i)
    r.append(len(df[df['Rating']==i]))
    
# Plotting a countplot pie chart for ratings
fig_pie = px.pie(values=r, names=l, title='Rating Distribution of Data')
fig_pie.show()

sns.countplot(df['YDate'])

# Plot and visualize the counts of sentiment analysis
plt.figure(figsize=(12,8))
plt.title('Year Distribution')
plt.xlabel('Year')
plt.ylabel('Count')
df['YDate'].value_counts().plot(kind='bar', color=['blue', 'green', 'red']) 

plt.show()

class_dist = df['Country'].value_counts()

def ditribution_plot(x,y,name):
    fig = go.Figure([
        go.Bar(x=x, y=y)
    ])

    fig.update_layout(title_text=name)
    fig.show()

ditribution_plot(x= class_dist.index, y= class_dist.values, name= 'Country Distribution')

# Plot the Country WordCloud 
countryWC = df['Country']

plt.figure(figsize=(15,7))
plt.title('Positive Word Cloud (Cleaned)')
allWords = ' '.join([twts for twts in countryWC])
wordCloud = WordCloud(background_color='white', width=1920, height=1080, random_state = 2, max_font_size=150).generate(allWords)

plt.imshow(wordCloud, interpolation = "bilinear")
plt.axis('off')
plt.savefig('cleaned_reviews_positive_wordcloud.png')
plt.show()

sns.countplot(df['Travel Status'])

class_dist = df['Travel Status'].value_counts()

def ditribution_plot(x,y,name):
    fig = go.Figure([
        go.Bar(x=x, y=y)
    ])

    fig.update_layout(title_text=name)
    fig.show()

ditribution_plot(x= class_dist.index, y= class_dist.values, name= 'Travel Status Distribution')

"""

> Exploratary Sentiment Data Analysis

"""

# Plot and visualize the counts of sentiment analysis
plt.figure(figsize=(12,8))
plt.title('Sentiment Analysis')
plt.xlabel('Sentiment')
plt.ylabel('Count')
df['Analysis'].value_counts().plot(kind='bar', color=['blue', 'green', 'red']) 

plt.show()

# Violin plot of Rating and Sentiment Score with box plot embedded in it
fig = go.Figure()

Ratings = [1,2,3,4,5]

for rating in Ratings:
    fig.add_trace(go.Violin(x=df['Rating'][df['Rating'] == rating],
                            y=df['Polarity'][df['Rating'] == rating],
                            name=rating,
                            box_visible=True,
                            meanline_visible=True))
    
fig.show()

# Grouping the data on the basis on Rating and Sentiment and counting the sentiment score
data2=df.groupby(['Rating','Sentiment'])['Polarity'].count()


# X here is the Ratings and Y is the Sentiment
X=[i[0] for i in data2.index.values]
Y=[i[1] for i in data2.index.values]

# Plotting the Bar Graph 
fig = px.bar(x=X, y=data2.values, color=Y, title="Sentiment Distribution WRT Ratings",labels={'x':'Ratings','y':'Total Number'})
fig.show()

# Plot the Positive Reviews WordCloud 
previews = df[df.Analysis == 1]
previews = previews['Review_clean']

plt.figure(figsize=(15,7))
plt.title('Positive Word Cloud (Cleaned)')
allWords = ' '.join([twts for twts in previews])
wordCloud = WordCloud(background_color='white', width=1920, height=1080, random_state = 21, max_font_size=150).generate(allWords)

plt.imshow(wordCloud, interpolation = "bilinear")
plt.axis('off')
plt.savefig('cleaned_reviews_positive_wordcloud.png')
plt.show()

# Plot the Negative Reviews WordCloud 
nreviews = df[df.Analysis == -1]
nreviews = nreviews['Review_clean']

plt.figure(figsize=(15,7))
plt.title('Negative Word Cloud (Cleaned)')
allWords = ' '.join([twts for twts in nreviews])
wordCloud = WordCloud(background_color='white', width=1920, height=1080, random_state = 21, max_font_size=150).generate(allWords)

plt.imshow(wordCloud, interpolation = "bilinear")
plt.axis('off')
plt.savefig('cleaned_reviews_negative_wordcloud.png')
plt.show()

# Plot the polarity and subjectivity
plt.figure(figsize=(12,8))
for i in range(0, df.shape[0]): 
  plt.scatter(df['Polarity'][i], df['Subjectivity'][i], color='Blue')

plt.title('Sentiment Analysis')
plt.xlabel('Polarity')
plt.ylabel('Subjectivity')
plt.show()

# Jointplot on the basis of Rating and Sentiment Score of the data
sns.jointplot(data=df,x='Rating',y='Polarity',kind='reg',color='orange')

"""#TEXT ANALYSIS"""

def wordCloud_generator(df, title=None):
    wordcloud = WordCloud(width = 1280, height = 720,
                          background_color ='black',
                          max_font_size = 300
                         ).generate(" ".join(df.values))
    # plot the WordCloud image                        
    plt.figure(figsize = (15, 7), facecolor = None) 
    plt.imshow(wordcloud, interpolation='bilinear') 
    plt.axis("off") 
    plt.tight_layout(pad = 0) 
    plt.title(title,fontsize=30)
    plt.show() 

wordCloud_generator(df['Review'], title="Most used words in reviews (Uncleaned)")

# Plot the word cloud 
plt.figure(figsize=(15,7))
plt.title('Most Used Words in Reviews (Cleaned)')
allWords = ' '.join([twts for twts in reviews_count_list])
wordCloud = WordCloud(background_color='white', width=1920, height=1080, random_state = 21, max_font_size=300).generate(allWords)

plt.imshow(wordCloud, interpolation = "bilinear")
plt.axis('off')
plt.savefig('cleaned_review_wordcloud.png')
plt.show()

# Top 25 used Review Words in Review_clean
top_25_reviews = Counter(reviews_count_list).most_common()
top_25_reviews = top_25_reviews[0:25]

# Put our findings in dataframe for further visualizations
sub_plot=pd.DataFrame(top_25_reviews)
sub_plot.rename(columns={0:'Review Words', 1:'Count'}, inplace=True)

# Use barplot for this visualization
plt.figure(figsize=(12,8))
viz_1=sns.barplot(x='Review Words', y='Count', data=sub_plot)
viz_1.set_title('Counts of the Top 25 Most Used Review Words')
viz_1.set_ylabel('Count of Review Words')
viz_1.set_xlabel('Review Words')
viz_1.set_xticklabels(viz_1.get_xticklabels(), rotation=80)

# Top 25 used Review Ngrams in Review_clean
top_25_ngrams = Counter(everygrams(reviews_count_list, min_len=2, max_len=4)).most_common(25)

# Put our findings in dataframe for further visualizations
sub_plot=pd.DataFrame(top_25_ngrams)
sub_plot.rename(columns={0:'Reviews N-gram', 1:'Count'}, inplace=True)

# Use barplot for this visualization
plt.figure(figsize=(12,8))
viz_1=sns.barplot(x='Reviews N-gram', y='Count', data=sub_plot)
viz_1.set_title('Counts of the Top 25 Most Used Review Paired-Words')
viz_1.set_ylabel('Count of Reviews N-gram')
viz_1.set_xlabel('Reviews N-gram')
viz_1.set_xticklabels(viz_1.get_xticklabels(), rotation=80)

"""#SENTIMENT ANALYSIS: MACHINE LEARNING BASED APPROACH (CLASSIFICATION)

> MODELING & EVALUATION
"""

# Create a function to compute the negative, neutral and positive analysis
def getAnalysis(score): 
  if score < 0: 
    return "Negative" 
  elif score == 0:
    return "Positive" 
  else:
    return "Positive" 
  
df['SentimentML'] = df['Polarity'].apply(getAnalysis)

df.head(10)

# Save into the clean dataset

df.to_csv('Capstone2_FinalReport_Dataset_Clean.csv')

docs = list(df['Review_clean'])[:7000]

# settings that you use for count vectorizer will go here 
tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_features = 20000) 
 
# just send in all your docs here 
tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(docs)

X = tfidf_vectorizer_vectors.toarray()
Y = df['SentimentML'][:7000]

len(X[0])

SEED=123

X_train,X_test,y_train,y_test=train_test_split(X, Y, test_size=0.2, random_state=SEED, stratify=Y)

"""

> Decision Tree Classifier

"""

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=SEED)
dt.fit(X_train,y_train)
y_pred_test = dt.predict(X_test)

print("Decision Tree Classifier","\n")
print(classification_report(y_test, y_pred_test, target_names=['positive', 'negative']))
print("---------------")
print("Training Accuracy score: "+str(round(accuracy_score(y_train,dt.predict(X_train)),4)))
print("Testing Accuracy score: "+str(round(accuracy_score(y_test,dt.predict(X_test)),4)))
print("---------------","\n")

cm = confusion_matrix(y_test, y_pred_test)
print('Decision Tree Confusion matrix\n\n', cm)
print('\n')
cm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Positive'], 
                        index=['Predict Negative', 'Predict Positive'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

"""

> Gaussian Naive Bayes Classifier

"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
gnb.fit(X_train, y_train)
y_pred_train = gnb.predict(X_train)
y_pred_test = gnb.predict(X_test)

print("Gaussian Naive Bayes (NB) Classifier","\n")
print(classification_report(y_test, y_pred_test, target_names=['positive', 'negative']))
print("---------------")
print("Training Accuracy score: "+str(round(accuracy_score(y_train,gnb.predict(X_train)),4)))
print("Testing Accuracy score: "+str(round(accuracy_score(y_test,gnb.predict(X_test)),4)))
print("---------------","\n")

cm = confusion_matrix(y_test, y_pred_test)
print('Gaussian Naive Bayes (NB) Confusion matrix\n\n', cm)
print('\n')
cm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Positive'], 
                        index=['Predict Negative', 'Predict Positive'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

"""Multinomial naive Bayes assumes to have feature vector where each element represents the number of times it appears (or, very often, its frequency). This technique is very efficient in natural language processing or whenever the samples are composed starting from a common dictionary. 

The Gaussian Naive Bayes, instead, is based on a continuous distribution and itâ€™s suitable for more generic classification tasks.

In summary, Naive Bayes classifier is a general term which refers to conditional independence of each of the features in the model, while Multinomial Naive Bayes classifier is a specific instance of a Naive Bayes classifier which uses a multinomial distribution for each of the features.

> Logistic Regression
"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(random_state=SEED).fit(X_train, y_train)
y_pred_train = lr.predict(X_train)
y_pred_test = lr.predict(X_test)

print("Logistic Regression Classifier","\n")
print(classification_report(y_test, y_pred_test, target_names=['positive', 'negative']))
print("---------------")
print("Training Accuracy score: "+str(round(accuracy_score(y_train,lr.predict(X_train)),4)))
print("Testing Accuracy score: "+str(round(accuracy_score(y_test,lr.predict(X_test)),4)))
print("---------------","\n")

cm = confusion_matrix(y_test, y_pred_test)
print('Logistic Regression Confusion matrix\n\n', cm)
print('\n')
cm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Positive'], 
                        index=['Predict Negative', 'Predict Positive'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

"""#DEPLOYMENT

#PICKING THE BEST MODEL

> Ensemble Learning/Modelling or Ensembling

> Random Forest Classifier (Bagging Ensemble Classifer)
"""

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=20)
clf.fit(X_train, y_train)
y_pred_train = clf.predict(X_train)
y_pred_test = clf.predict(X_test)

print("Random Forest (Bagging Ensemble) Classifer","\n")
print(classification_report(y_test, y_pred_test, target_names=['positive', 'negative']))
print("---------------")
print("Training Accuracy score: "+str(round(accuracy_score(y_train,clf.predict(X_train)),4)))
print("Testing Accuracy score: "+str(round(accuracy_score(y_test,clf.predict(X_test)),4)))
print("---------------","\n")

cm = confusion_matrix(y_test, y_pred_test)
print('Random Forest (Bagging Ensemble) Confusion matrix\n\n', cm)
print('\n')
cm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Positive'], 
                        index=['Predict Negative', 'Predict Positive'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

"""

> Boosting Classifer

"""

#Boosting - Ada Boost
from sklearn.ensemble import AdaBoostClassifier
adb = AdaBoostClassifier(DecisionTreeClassifier(),n_estimators = 5, learning_rate = 1)
adb.fit(X_train,y_train)
y_pred_train = adb.predict(X_train)
y_pred_test = adb.predict(X_test)

print("AdaBoost (Boosting Ensemble) Classifer")
print("Boost using Decision Tree","\n")
print(classification_report(y_test, y_pred_test, target_names=['positive', 'negative']))
print("---------------")
print("Training Accuracy score: "+ str(round(adb.score(X_train,y_train),4)))
print("Testing Accuracy score: "+ str(round(adb.score(X_test,y_test),4)))
print("---------------","\n")

cm = confusion_matrix(y_test, y_pred_test)
print('AdaBoost (Boosting Ensemble) Confusion matrix\n\n', cm)
print('\n')
cm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Positive'], 
                        index=['Predict Negative', 'Predict Positive'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

"""

> Voting Classifier

"""

from sklearn.ensemble import VotingClassifier

classifiers = [('Decision Tree', dt),
               ('Logistic Regression', lr),
                ('Gaussian Naive Bayes', gnb)
              ]
vc = VotingClassifier(estimators=classifiers)
# Fit 'vc' to the traing set and predict test set labels
vc.fit(X_train, y_train)
y_pred_train = vc.predict(X_train)
y_pred_test = vc.predict(X_test)

print("Voting Ensambling Classifier\n")
print("Combining Three Classifiers")
print("1. Decision Tree 2. Logistic Regression 3. Gaussian Naive Bayes\n")
print(classification_report(y_test, y_pred_test, target_names=['positive', 'negative']))
print("---------------","\n")
print("Training Accuracy score: "+str(round(accuracy_score(y_train,vc.predict(X_train)),4)))
print("Testing Accuracy score: "+str(round(accuracy_score(y_test,vc.predict(X_test)),4)))
print("---------------","\n")

cm = confusion_matrix(y_test, y_pred_test)
print('Voting Ensemble Confusion matrix\n\n', cm)
print('\n')
cm_matrix = pd.DataFrame(data=cm, columns=['Actual Negative', 'Actual Positive'], 
                        index=['Predict Negative', 'Predict Positive'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

"""Ensemble Learning / Ensembling can remove the bias of data or model. 

Ensemble Learning is using multiple learning algorithms at a time, to obtain predictions with an aim to have better predictions than the individual models.

Ensemble learning is a very popular method to improve the accuracy of a machine learning model. 
It avoid overfitting and gives us a much better model. 
bootstrap aggregating (Bagging) and boosting are popular ensemble methods. 
"""